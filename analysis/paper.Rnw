\documentclass{article}
\usepackage{amsmath}
\usepackage{url}
\usepackage{enumitem}
\usepackage{lipsum}
\usepackage{tikz}
\usepackage{adjustbox}
\title{Estimating Social Segregation}
\author{Forest Gregg}

\usetikzlibrary{arrows}
\usetikzlibrary{bayesnet}

\DeclareMathOperator*{\argmin}{\arg\!\min}
\DeclareMathOperator*{\argmax}{\arg\!\max}

\begin{document}
\maketitle

<<include=FALSE>>=
library(knitr)
library(RPostgreSQL)
library(xtable)
library(RcppCNPy)
opts_chunk$set(
echo=F, fig.width=4.5, fig.height=4.75, fig.path='/home/fgregg/sweave-cache/figs/fig', cache=T, results='hide'
)
knit_hooks$set(inline = function(x) {
  prettyNum(x, big.mark=",")
})
@ 

Sociologists know that large scale patterns can emerge from the
local, mutual influence of individuals. From thought experiments and
simulations, we can see how racial segregation, flocking behavior, or
public order on the street could emerge from individuals making
simple, local adjustments to one another. Yet, while emergentist thinking
has been attractive to sociologists for a long time, there has been no
substantial empirical program to develop and test theories of how local
influence result in global patterns. There are couple of reasons.

First, in many social settings, we cannot statistically identify local
influence. We cannot tell whether Alice jumped off the bridge because
that's what her friend Bob did. Maybe Alice jumped because Alice and
Bob are both bridge-jumping enthusiasts and that's why they are
friends. If we do not have an adequate model of why two people are
interacting, we cannot distinguish the effects of that interaction
from unobserved homophily.\footnote{shalizi, homophily}

Second, models with coupled, interdependent units are computationally
harder to estimate than models with independence.  For models with
interdependent, discrete outcomes, the estimation has been beyond the
realm of practical computation.\footnote{foo}

For the first problem, space is very useful. For many social processes
that occur in geographic space, we can reasonably posit that the
influencing units are either immediate neighbors or fall with some
fixed distance of each other.\footnote{grannis} Because we have a
model of which units influence one another, we can identify the
effects of that influence.

For the second problem, new methods from computer vision now make it
possible to estimate large systems of coupled, discrete
variables. Using these methods, we will bring observational data to
bear the most famous formal model of emergent order in urban
sociology, the Schelling model of segregation.

\section{intro to Schelling}
In his 1971 paper ``Dynamic Models of Segregation'' Thomas Schelling
showed that complete residential racial segregation could emerge
through people preferring, even slightly, to live in houses surrounded
mostly by neighbors of their same race.

In his model, residential locations were divided into a
checkerboard. At the beginning, white and black agents are distributed
randomly across the board. There are more locations than there are
agents, so there are vacant locations. Agents are discontent if a
certain percentage of their neighbors or not of the same color. Time
proceeds in steps.  At every step, all the individuals who were
discontent at the end of the last step move to the nearest location
that makes them content.

Schelling ran a series of variations, changing the number of vacancies,
the number of neighbors that the agent considered relevant, and the
intensity of color preference. In every variant, after enough time
steps, the white and black agents are spatially segregated. 

While his piece is about racial segregation, Schelling does not
attempt to model the actual observed racial segregation of American
cities. While the results of Schelling's models resemble maps of
racial segregation in American cities, he had no way to test whether
his models were consistent with observed reality. That only became
feasible in the 2000s with the development of a method called
Structured Support Vector Machines.

\input{theory_and_math.tex}

\section*{Estimating Racial Preferences}
We now estimate the racial frustration costs from the observed
residential patterns of the 49 most populous American counties (Table~\ref{tab:counties}) .

From the 2010-2015 ACS 5-Year Estimates, we pull the population of
Hispanics, Non-Hispanic Whites, and Non-Hispanic African Americans for
every block group in all the counties.\footnote{Census API} For every
blockgroup, we label the block group as Hispanic, White, or Black
based on which group is most common in the block group.  Using the
associated 2014 TIGER/Line Shapefiles, we calculate the adjacency
matrix for the
blockgroups\footnote{https://www.census.gov/geo/maps-data/data/tiger.html,
  PySAL}.

We'll use these data to estimate the parameters of the following score
function. 

\begin{align}
\operatorname{E}(\mathbf{y}) = \sum_{<i
  j>}^{\mathcal{N}}\epsilon_{i,j}(y_i,y_j) + \sum_i^N\epsilon_i(y_i)
\end{align}

Where 

\begin{align}
  \epsilon_{i,j} = w_0\operatorname{WW}(x_{i}, x_{j}) +
  w_1\operatorname{WB}(x_{i}, x_{j}) + 
  w_2\operatorname{WH}(x_{i}, x_{j}) +
  w_3\operatorname{BB}(x_i, x_j) +
  w_4\operatorname{BH}(x_i, x_j) +
  w_5\operatorname{HH}(x_i, x_j) +
\end{align} 

and $\operatorname{WW}$ indicates that block $i$ and $j$ are both
labeled as ``White''; $\operatorname{WB}$ indicates a ``White'' block
and ``Black'' block; $\operatorname{WH}$ indicates indicates a
``White'' block and ``Hispanic'' block; and so on.

In addition, 


\begin{align}
  \e_{i} = b_0 + b_1\operatorname{B_1}(y_{i}) 
          b_2\operatorname{H_1}(y_{i}) + b_3\operatorname{B_2}(y_{i}) 
          + b_4\operatorname{B_2}(y_{i}) + b_5\operatorname{H_2}(y_{i}) 
          + ... + b_{144}\operatorname{B_{49}}(y_{i}) +
          b_{145}\operatorname{B_{49}}(y_i) + b_{146}\operatorname(H_{49}}(y_i)
\end{align}

where $\operatorname{W_k}$, $\operatorname{B_k}$, $\operatorname{H_k}$
are indicator functions for whether a block is labeled as white,
black, or Hispanic. Since every county has a different racial mix, we
need a set indicator variables for each county. These weights affect
how we would label a block if we didn't know anything about it's neighbors.

We estimate all the parameters using the PyStruct library. In order to
evaluate the robustness of the parameters, we bootstrap a sampling
distribution of the parameters by sampling with replacement from the
49 counties, estimating the parameters on the sample, recording the
results, and repeating 1000 times.

<<countyTable, results='asis'>>=
library(RPostgreSQL)
con <- DBI::dbConnect(RPostgreSQL::PostgreSQL(), dbname="segregation")

counties <- DBI::dbGetQuery(con, 
    "SELECT name[3] || ', ' || name[4] AS place, 
            SUM(total)::INT AS population,
            SUM(white)::INT AS white,
            SUM(black)::INT AS black,
            SUM(hispanic)::INT AS hispanic
     FROM (SELECT REGEXP_SPLIT_TO_ARRAY(\"NAME\", ', ') AS name, 
                  \"B03002_001E\" AS total,
	          \"B03002_003E\" as white, 
	          \"B03002_004E\" as black, 
                  \"B03002_012E\" as hispanic
           FROM race) AS t 
     GROUP BY name[3] || ', ' || name[4] ORDER BY SUM(total) DESC")

names(counties) <- c("County", "Total Population", "White", "Black", "Hispanic")

print(xtable(counties,
             caption="Populations of 49 Largest Counties",
             label="tab:counties"),
      format.args = list(big.mark = ","),
      include.rownames=FALSE)
@ 

<<bootstrap>>=
library(RcppCNPy)

load <- function(x) {
    filename = paste0(x, '.npy')
    npyLoad(filename)
}

ww <- load('white-white')
bw <- load('black-white')
hw <- load("hispanic-white")
bb <- load("black-black")
hb <- load("hispanic-black")
hh <- load("hispanic-hispanic")


par(mfrow=c(3,3))
hist(ww)
hist(bw)
hist(hw)
plot.new()
hist(bb)
hist(hb)
plot.new()
plot.new()
hist(hh)
par(mfrow=c(1,1))

@ 


\end{document}

\footnote{We can also use these
  techniques on scoring functions that have a term for the relation
  between the properties of a particular block and the region
  assignment, $\epsilon_i(y_i)$. This is particularly useful when we
  already know something about what meaningful categories should exist.

  \begin{align}
    \operatorname{E}(\mathbf{y}) = \sum_i^N\epsilon_i(y_i) + \sum_{<i j>}^{\mathcal{N}}\epsilon_{i,j}(y_i,y_j)
  \end{align}

  For example, if we had a strong, ecological theory of urban space,
  we might want to identify regions like `the red light district,'
  `the zone of industry`, `the central business district.' We would
  want to pay a large penalty if we assigned a block that had lot of
  immigrants to `the central business district` instead of `the
  immigrant neighborhood.'
}

